{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "vUsAQ1-ekpJo"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from torch.utils.data.dataset import random_split, TensorDataset\n",
        "from torchvision import datasets\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_train = pd.read_csv('train.csv')\n",
        "data_train_len = data_train.shape[0]\n",
        "data_test = pd.read_csv('test.csv')\n",
        "y = data_train.pop('Attrition')\n",
        "data = pd.concat([data_train, data_test])\n",
        "\n",
        "data = data.drop(columns=['EmployeeID', 'StandardHours', 'Over18', 'EmployeeCount'])\n",
        "data.replace({'JobRole':{'Admin': 'Administrative'}}, inplace=True)\n",
        "# for colname in data.select_dtypes(\"O\"):\n",
        "#     data[colname], _ = data[colname].factorize()\n",
        "data.replace({'Education':{1:'Below_college', 2:'College', 3:'Bachelor', 4:'Masters', 5:'Doctor'}}, inplace=True)\n",
        "data = pd.get_dummies(data)\n",
        "data = data.drop(columns=['Gender_Female','OverTime_No'])\n",
        "\n",
        "train = data.iloc[:data_train_len, :]\n",
        "test = data.iloc[data_train_len:, :]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1340, 48)"
            ]
          },
          "execution_count": 97,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {},
      "outputs": [],
      "source": [
        "def y_enco(y):\n",
        "    if y == 'No':\n",
        "        return 0\n",
        "    elif y == 'Yes':\n",
        "        return 1\n",
        "    else:\n",
        "        pass\n",
        "\n",
        "y_encoder = y.apply(y_enco)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2116, 48)"
            ]
          },
          "execution_count": 99,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from imblearn.over_sampling import ADASYN \n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "# Data Normalization\n",
        "\n",
        "scaler = MinMaxScaler(feature_range = (0,1))\n",
        "scaler.fit(train)\n",
        "X_norm = scaler.transform(train)\n",
        "\n",
        "ada = ADASYN(random_state=42)\n",
        "X_res, y_res = ada.fit_resample(X_norm, y_encoder)\n",
        "X_res.shape\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size=0.1, random_state=42)\n",
        "X_train.shape\n",
        "# ada = ADASYN(random_state=42)\n",
        "# X_res, y_res = ada.fit_resample(X_train, y_train)\n",
        "# X_res.shape, y_res.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "id": "9jPK_vcprZK2"
      },
      "outputs": [],
      "source": [
        "X_data = torch.tensor(X_train, dtype = torch.float)\n",
        "y_data = torch.tensor(y_train.to_numpy().reshape((-1,1)), dtype = torch.float)\n",
        "\n",
        "dataset = TensorDataset(X_data, y_data)\n",
        "\n",
        "# train_set, val_set = random_split(dataset, [1071, 269])\n",
        "train_set, val_set = random_split(dataset, [1500, 616])\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_set, batch_size=128, shuffle=True)\n",
        "val_loader = torch.utils.data.DataLoader(val_set, batch_size=128, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {
        "id": "zN56cuv5k0jK"
      },
      "outputs": [],
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.fc1 = nn.Linear(48, 100)\n",
        "        self.fc2 = nn.Linear(100, 100)\n",
        "        self.fc3 = nn.Linear(100, 100)\n",
        "        self.fc4 = nn.Linear(100, 100)\n",
        "        self.fc5 = nn.Linear(100, 100)\n",
        "        self.fc6 = nn.Linear(100, 100)\n",
        "        self.fc7 = nn.Linear(100, 1)\n",
        "        self.dropout = nn.Dropout(p=0.2)\n",
        "    def forward(self, x):\n",
        "        x = torch.sigmoid(self.fc1(x))\n",
        "        #x = self.dropout(x)\n",
        "        x = F.softplus(self.fc2(x))\n",
        "        #x = self.dropout(x)\n",
        "        x = F.softplus(self.fc3(x))\n",
        "        #x = self.dropout(x)\n",
        "        x = F.softplus(self.fc4(x))\n",
        "        #x = self.dropout(x)\n",
        "        x = F.softplus(self.fc5(x))\n",
        "        x = F.softplus(self.fc6(x))\n",
        "        x = torch.sigmoid(self.fc7(x))\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DjagsifJk1T0",
        "outputId": "653fcb91-5b4b-4d40-f113-0d754fed0101"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train on GPU...\n"
          ]
        }
      ],
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "if device =='cuda':\n",
        "    print(\"Train on GPU...\")\n",
        "else:\n",
        "    print(\"Train on CPU...\")\n",
        "max_epochs = 80"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257
        },
        "id": "xE-fQpi3k1M0",
        "outputId": "78cb8a7f-bb41-4e5b-dbac-519aa03604d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[epoch 1] loss: 0.29093 val loss: 0.25232\n",
            "[epoch 2] loss: 0.25913 val loss: 0.25398\n",
            "[epoch 3] loss: 0.25282 val loss: 0.24999\n",
            "[epoch 4] loss: 0.24940 val loss: 0.24899\n",
            "[epoch 5] loss: 0.22490 val loss: 0.19079\n",
            "[epoch 6] loss: 0.14015 val loss: 0.10574\n",
            "[epoch 7] loss: 0.09870 val loss: 0.07969\n",
            "[epoch 8] loss: 0.08598 val loss: 0.07255\n",
            "[epoch 9] loss: 0.08641 val loss: 0.08812\n",
            "[epoch 10] loss: 0.08007 val loss: 0.06891\n",
            "[epoch 11] loss: 0.07780 val loss: 0.07427\n",
            "[epoch 12] loss: 0.07225 val loss: 0.07334\n",
            "[epoch 13] loss: 0.07094 val loss: 0.06469\n",
            "[epoch 14] loss: 0.06807 val loss: 0.06575\n",
            "[epoch 15] loss: 0.06944 val loss: 0.06286\n",
            "[epoch 16] loss: 0.06457 val loss: 0.07405\n",
            "[epoch 17] loss: 0.06736 val loss: 0.07354\n",
            "[epoch 18] loss: 0.06288 val loss: 0.06416\n",
            "[epoch 19] loss: 0.06459 val loss: 0.05872\n",
            "[epoch 20] loss: 0.06183 val loss: 0.05841\n",
            "[epoch 21] loss: 0.05626 val loss: 0.05890\n",
            "[epoch 22] loss: 0.05396 val loss: 0.05908\n",
            "[epoch 23] loss: 0.05824 val loss: 0.05756\n",
            "[epoch 24] loss: 0.05884 val loss: 0.05793\n",
            "[epoch 25] loss: 0.05739 val loss: 0.05785\n",
            "[epoch 26] loss: 0.05643 val loss: 0.05718\n",
            "[epoch 27] loss: 0.05468 val loss: 0.05727\n",
            "[epoch 28] loss: 0.05468 val loss: 0.05694\n",
            "[epoch 29] loss: 0.05329 val loss: 0.05724\n",
            "[epoch 30] loss: 0.05683 val loss: 0.05667\n",
            "[epoch 31] loss: 0.05703 val loss: 0.05649\n",
            "[epoch 32] loss: 0.05181 val loss: 0.05672\n",
            "[epoch 33] loss: 0.05399 val loss: 0.05671\n",
            "[epoch 34] loss: 0.05594 val loss: 0.05702\n",
            "[epoch 35] loss: 0.05278 val loss: 0.05743\n",
            "[epoch 36] loss: 0.05306 val loss: 0.05648\n",
            "[epoch 37] loss: 0.05335 val loss: 0.05671\n",
            "[epoch 38] loss: 0.05448 val loss: 0.05679\n",
            "[epoch 39] loss: 0.06039 val loss: 0.05607\n",
            "[epoch 40] loss: 0.05277 val loss: 0.05628\n",
            "[epoch 41] loss: 0.05434 val loss: 0.05667\n",
            "[epoch 42] loss: 0.05359 val loss: 0.05662\n",
            "[epoch 43] loss: 0.05447 val loss: 0.05652\n",
            "[epoch 44] loss: 0.05293 val loss: 0.05656\n",
            "[epoch 45] loss: 0.04975 val loss: 0.05644\n",
            "[epoch 46] loss: 0.05385 val loss: 0.05635\n",
            "[epoch 47] loss: 0.05305 val loss: 0.05628\n",
            "[epoch 48] loss: 0.05357 val loss: 0.05611\n",
            "[epoch 49] loss: 0.05385 val loss: 0.05629\n",
            "[epoch 50] loss: 0.05251 val loss: 0.05636\n",
            "[epoch 51] loss: 0.05251 val loss: 0.05631\n",
            "[epoch 52] loss: 0.05117 val loss: 0.05640\n",
            "[epoch 53] loss: 0.05289 val loss: 0.05616\n",
            "[epoch 54] loss: 0.05149 val loss: 0.05630\n",
            "[epoch 55] loss: 0.05284 val loss: 0.05624\n",
            "[epoch 56] loss: 0.05294 val loss: 0.05634\n",
            "[epoch 57] loss: 0.05347 val loss: 0.05622\n",
            "[epoch 58] loss: 0.05144 val loss: 0.05617\n",
            "[epoch 59] loss: 0.05592 val loss: 0.05618\n",
            "[epoch 60] loss: 0.05283 val loss: 0.05627\n",
            "[epoch 61] loss: 0.05120 val loss: 0.05626\n",
            "[epoch 62] loss: 0.05409 val loss: 0.05625\n",
            "[epoch 63] loss: 0.05542 val loss: 0.05626\n",
            "[epoch 64] loss: 0.05278 val loss: 0.05628\n",
            "[epoch 65] loss: 0.05390 val loss: 0.05629\n",
            "[epoch 66] loss: 0.05578 val loss: 0.05631\n",
            "[epoch 67] loss: 0.05017 val loss: 0.05632\n",
            "[epoch 68] loss: 0.05586 val loss: 0.05633\n",
            "[epoch 69] loss: 0.05355 val loss: 0.05635\n",
            "[epoch 70] loss: 0.05208 val loss: 0.05636\n",
            "[epoch 71] loss: 0.05630 val loss: 0.05633\n",
            "[epoch 72] loss: 0.05094 val loss: 0.05633\n",
            "[epoch 73] loss: 0.05254 val loss: 0.05630\n",
            "[epoch 74] loss: 0.05090 val loss: 0.05630\n",
            "[epoch 75] loss: 0.05386 val loss: 0.05631\n",
            "[epoch 76] loss: 0.05297 val loss: 0.05632\n",
            "[epoch 77] loss: 0.05229 val loss: 0.05631\n",
            "[epoch 78] loss: 0.05625 val loss: 0.05633\n",
            "[epoch 79] loss: 0.05378 val loss: 0.05632\n",
            "[epoch 80] loss: 0.05456 val loss: 0.05632\n"
          ]
        }
      ],
      "source": [
        "loss_list, acc_list = [], []\n",
        "\n",
        "criterion = nn.MSELoss()\n",
        "net = Net().to(device)\n",
        "optimizer = optim.Adam(net.parameters(), lr=0.01)\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.1)\n",
        "\n",
        "for epoch in range(max_epochs):\n",
        "    net.train()\n",
        "    epoch_loss = 0.0\n",
        "    for batch_idx, (data, labels) in enumerate(train_loader):\n",
        "        data, labels = data.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        output = net(data)\n",
        "        loss = criterion(output, labels)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss\n",
        "\n",
        "    avg_loss = epoch_loss/(batch_idx+1)\n",
        "    loss_list.append(avg_loss.cpu().detach().numpy())\n",
        "\n",
        "    # validation\n",
        "    net.eval()\n",
        "    with torch.no_grad():\n",
        "        loss_val = 0.0\n",
        "        correct_val = 0\n",
        "        for batch_idx, (data, labels) in enumerate(val_loader):\n",
        "            data, labels = data.to(device), labels.to(device)\n",
        "            output = net(data)\n",
        "            loss = criterion(output, labels)\n",
        "  \n",
        "            loss_val += loss\n",
        "            \n",
        "        avg_loss_val = loss_val/(batch_idx+1)\n",
        "        avg_acc_val = correct_val/(len(val_loader.dataset))\n",
        "        \n",
        "    scheduler.step()\n",
        "\n",
        "    print('[epoch %d] loss: %.5f val loss: %.5f' % (epoch + 1, avg_loss,  avg_loss_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([336, 48])"
            ]
          },
          "execution_count": 130,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "scaler.fit(test)\n",
        "\n",
        "X_test_scaler = scaler.transform(test)\n",
        "X_test_scaler = torch.tensor(X_test_scaler, dtype=torch.float).to(device)\n",
        "X_test_scaler.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_pred = net(X_test_scaler).cpu().detach().numpy()\n",
        "y_pred_show = np.zeros((y_pred.shape), dtype = int)\n",
        "for i in range(y_pred.shape[0]):\n",
        "    if y_pred[i] >= 0.5:\n",
        "        y_pred_show[i] = 1\n",
        "    else:\n",
        "        y_pred_show[i] = 0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {},
      "outputs": [],
      "source": [
        "id = range(0,len(y_pred_show))\n",
        "y_test = pd.DataFrame()\n",
        "y_test['Id'] = id\n",
        "y_test['Predicted'] = y_pred_show\n",
        "y_test.to_csv('pred_dnn_ad.csv', index = 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.9619047619047619\n",
            "1.0\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import f1_score\n",
        "for x,y in test_loader:\n",
        "    x = x.to(device)\n",
        "\n",
        "    y_pred_val = net(x).cpu().detach().numpy()\n",
        "    y_pred_show = np.zeros((y_pred_val.shape), dtype = int)\n",
        "    for i in range(y_pred_val.shape[0]):\n",
        "        if y_pred_val[i] >= 0.5:\n",
        "            y_pred_show[i] = 1\n",
        "        else:\n",
        "            y_pred_show[i] = 0\n",
        "\n",
        "    print(f1_score(y, y_pred_show))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.9.7 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "vscode": {
      "interpreter": {
        "hash": "22206c1fa60949d1e01011e2a752496908b73b24bb78e105f5fef6553e40794b"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
